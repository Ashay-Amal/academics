{"doi": "10.48550/arXiv.2111.02400", "date": "2021-11-01", "title": "Deep AUC Maximization for Medical Image Classification: Challenges and Opportunities", "authors": "Tianbao Yang", "abstract": "In this extended abstract, we will present and discuss opportunities and\nchallenges brought about by a new deep learning method by AUC maximization (aka\n\\underline{\\bf D}eep \\underline{\\bf A}UC \\underline{\\bf M}aximization or {\\bf\nDAM}) for medical image classification. Since AUC (aka area under ROC curve) is\na standard performance measure for medical image classification, hence directly\noptimizing AUC could achieve a better performance for learning a deep neural\nnetwork than minimizing a traditional loss function (e.g., cross-entropy loss).\nRecently, there emerges a trend of using deep AUC maximization for large-scale\nmedical image classification. In this paper, we will discuss these recent\nresults by highlighting (i) the advancements brought by stochastic non-convex\noptimization algorithms for DAM; (ii) the promising results on various medical\nimage classification problems. Then, we will discuss challenges and\nopportunities of DAM for medical image classification from three perspectives,\nfeature learning, large-scale optimization, and learning trustworthy AI models.", "journal": ""}
{"doi": "10.48550/arXiv.2307.10506", "date": "2023-07-20", "title": "Is Grad-CAM Explainable in Medical Images?", "authors": "Subhashis Suara, Aayush Jha, Pratik Sinha, Arif Ahmed Sekh", "abstract": "Explainable Deep Learning has gained significant attention in the field of\nartificial intelligence (AI), particularly in domains such as medical imaging,\nwhere accurate and interpretable machine learning models are crucial for\neffective diagnosis and treatment planning. Grad-CAM is a baseline that\nhighlights the most critical regions of an image used in a deep learning\nmodel's decision-making process, increasing interpretability and trust in the\nresults. It is applied in many computer vision (CV) tasks such as\nclassification and explanation. This study explores the principles of\nExplainable Deep Learning and its relevance to medical imaging, discusses\nvarious explainability techniques and their limitations, and examines medical\nimaging applications of Grad-CAM. The findings highlight the potential of\nExplainable Deep Learning and Grad-CAM in improving the accuracy and\ninterpretability of deep learning models in medical imaging. The code is\navailable in (will be available).", "journal": ""}
{"doi": "10.48550/arXiv.2109.05159", "date": "2021-09-11", "title": "Co-Correcting: Noise-tolerant Medical Image Classification via mutual Label Correction", "authors": "Jiarun Liu, Ruirui Li, Chuan Sun", "abstract": "With the development of deep learning, medical image classification has been\nsignificantly improved. However, deep learning requires massive data with\nlabels. While labeling the samples by human experts is expensive and\ntime-consuming, collecting labels from crowd-sourcing suffers from the noises\nwhich may degenerate the accuracy of classifiers. Therefore, approaches that\ncan effectively handle label noises are highly desired. Unfortunately, recent\nprogress on handling label noise in deep learning has gone largely unnoticed by\nthe medical image. To fill the gap, this paper proposes a noise-tolerant\nmedical image classification framework named Co-Correcting, which significantly\nimproves classification accuracy and obtains more accurate labels through\ndual-network mutual learning, label probability estimation, and curriculum\nlabel correcting. On two representative medical image datasets and the MNIST\ndataset, we test six latest Learning-with-Noisy-Labels methods and conduct\ncomparative studies. The experiments show that Co-Correcting achieves the best\naccuracy and generalization under different noise ratios in various tasks. Our\nproject can be found at: https://github.com/JiarunLiu/Co-Correcting.", "journal": ""}
